<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Verse</title>
    <!-- Tailwind CSS for modern styling -->
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body {
            /* Set font and ensure no overflow */
            font-family: 'Inter', sans-serif;
            overflow: hidden;
            height: 100vh;
            width: 100vw;
            cursor: none; /* Hide default cursor */
        }

        #custom-cursor {
            position: absolute;
            width: 30px;
            height: 30px;
            border-radius: 50%;
            background: radial-gradient(circle, rgba(255,255,255,0.8) 0%, rgba(56,189,248,0.4) 70%, transparent 71%);
            pointer-events: none;
            z-index: 9999;
            transform: translate(-50%, -50%);
            box-shadow: 0 0 15px 5px rgba(56, 189, 248, 0.6);
            display: none;
        }

        .build-btn, #send-btn {
            border: 1px solid #38bdf8;
        }

        #ui-overlay {
            /* Use a glassmorphism effect */
            backdrop-filter: blur(10px);
            background: rgba(15, 23, 42, 0.8);
        }

        /* Custom scrollbar for text areas */
        textarea::-webkit-scrollbar {
            width: 8px;
        }
        textarea::-webkit-scrollbar-track {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 10px;
        }
        textarea::-webkit-scrollbar-thumb {
            background: #38bdf8;
            border-radius: 10px;
        }
        textarea::-webkit-scrollbar-thumb:hover {
            background: #0ea5e9;
        }

        /* Loader animation */
        .loader {
            border-top-color: #3b82f6;
            animation: spin 1s linear infinite;
        }

        #videoSection {
            margin-top: 10px;;
        }

        @keyframes spin {
            to { transform: rotate(360deg); }
        }
    </style>
</head>
<body class="bg-gray-900 text-gray-100">
    <!-- Custom cursor element -->
    <div id="custom-cursor"></div>
    
    <!-- Main container for the 3D scene -->
    <div id="vr-container" class="relative w-full h-full">
        <canvas id="three-canvas" class="block w-full h-full"></canvas>
        
        <!-- UI overlay for controls and status -->
        <div id="ui-overlay" 
      class="absolute top-5 left-5 z-10 p-6 rounded-2xl shadow-xl border border-gray-700 max-w-xs w-[280px] transition-all duration-300">
            <h3 class="text-2xl font-bold text-sky-400 mb-4">AI Verse</h3>
            <div id="model-count" class="text-xs text-gray-400 mb-4">Selected Models: 0</div>
            <button id="build-btn" class="btn build-btn w-full mb-4 px-6 py-3 rounded-lg font-bold text-sm shadow-md transition-all duration-300 transform hover:scale-105 disabled:opacity-50 disabled:cursor-not-allowed">Build VR Chat UI</button>
            
            <div id="prompt-section" class="hidden">
                <textarea id="prompt-input" class="w-full h-24 p-3 rounded-lg border border-gray-600 bg-gray-800 text-gray-100 placeholder-gray-400 resize-y focus:outline-none focus:ring-2 focus:ring-sky-500 transition-all" placeholder="Enter your prompt for selected models..."></textarea>
                <button id="send-btn" class="btn w-full mt-4 px-6 py-3 rounded-lg font-bold text-sm shadow-md transition-all duration-300 transform hover:scale-105">Send to Models</button>
            </div>

            <div id="videoSection" style="display:none">
                Infer Frame:<input type="checkbox" id="inferChk" disabled><input type="file" id="videoUpload" accept="video/*"/>
                <video id="video" style="display:none" autoplay loop playsinline></video>
            </div>
            
            <div id="loader" class="loader w-8 h-8 mx-auto my-4 border-4 border-gray-600 border-t-sky-500 rounded-full animate-spin hidden"></div>
            <div id="status" class="text-xs text-center text-gray-400 mt-4">Loading models...</div>
        </div>
        
        <!-- Controls overlay -->
        <div class="absolute bottom-5 left-5 z-10 p-4 rounded-2xl shadow-xl border border-gray-700 bg-gray-900 bg-opacity-80 backdrop-blur-sm">
            <h4 class="font-bold text-gray-200 text-sm mb-2">Controls:</h4>
            <div class="text-xs text-gray-400 space-y-1">
                <p class="flex items-center"><svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4 mr-1 text-sky-400" viewBox="0 0 20 20" fill="currentColor"><path d="M10 12a2 2 0 100-4 2 2 0 000 4z"/><path fill-rule="evenodd" d="M.458 10C1.732 5.943 5.522 3 10 3s8.268 2.943 9.542 7c-1.274 4.057-5.064 7-9.542 7S1.732 14.057.458 10zM14 10a4 4 0 11-8 0 4 4 0 018 0z" clip-rule="evenodd"/></svg> Mouse: Look around</p>
                <p class="flex items-center"><svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4 mr-1 text-sky-400" viewBox="0 0 20 20" fill="currentColor"><path d="M5 4a2 2 0 012-2h6a2 2 0 012 2v14l-5-2.5L5 18V4z"/></svg> Left Click: Select models</p>
                <p class="flex items-center"><svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4 mr-1 text-sky-400" viewBox="0 0 20 20" fill="currentColor"><path d="M11 5.4a2 2 0 01-2.2 0l-4 2a2 2 0 00-1.8 1.8l-2 4a2 2 0 000 2.2l2 4a2 2 0 001.8 1.8l4 2a2 2 0 002.2 0l4-2a2 2 0 001.8-1.8l2-4a2 2 0 000-2.2l-2-4a2 2 0 00-1.8-1.8l-4-2zM8 12.5a.5.5 0 001 0V8a.5.5 0 00-1 0v4.5zm4-4a.5.5 0 00-1 0V11a.5.5 0 001 0v-2.5z"/></svg> WASD: Move camera</p>
                <p class="flex items-center"><svg xmlns="http://www.w3.org/2000/svg" class="h-4 w-4 mr-1 text-sky-400" viewBox="0 0 20 20" fill="currentColor"><path d="M10 12a2 2 0 100-4 2 2 0 000 4z"/><path fill-rule="evenodd" d="M.458 10C1.732 5.943 5.522 3 10 3s8.268 2.943 9.542 7c-1.274 4.057-5.064 7-9.542 7S1.732 14.057.458 10zM14 10a4 4 0 11-8 0 4 4 0 018 0z" clip-rule="evenodd"/></svg> Scroll: Zoom</p>
            </div>
        </div>
    </div>

    <!-- Script for Three.js and custom logic -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/coco-ssd"></script>
    <script>
        // Global variables for the Three.js scene and application state
        let scene, camera, renderer;
        let modelGroups = []; // Stores groups of a cube and its label for easy removal
        let selectedModels = [];
        let responseWindows = [];
        let allModels = [];
        let mouse = new THREE.Vector2();
        let raycaster = new THREE.Raycaster();
        let isBuilt = false;
        let highlightLight; // New variable for the single, dynamic light
        let torchLight; // New variable for the mouse torch light
        let cursorVisible = false;
        let cocoSsdModel = null;
        
        // Camera movement state
        let moveForward = false, moveBackward = false;
        let moveLeft = false, moveRight = false;
        let velocity = new THREE.Vector3();
        
        /**
         * Initializes the Three.js scene, camera, renderer, and lighting.
         */
        function init() {
            // Scene setup
            scene = new THREE.Scene();
            scene.background = new THREE.Color(0x0a0a0a);
            
            // Camera setup
            camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
            camera.position.set(0, 5, 10);
            
            // Renderer setup
            renderer = new THREE.WebGLRenderer({ canvas: document.getElementById('three-canvas'), antialias: true });
            renderer.setSize(window.innerWidth, window.innerHeight);
            renderer.shadowMap.enabled = true;
            renderer.shadowMap.type = THREE.PCFSoftShadowMap;
            
            // Reverted to a single AmbientLight for general scene illumination
            const ambientLight = new THREE.AmbientLight(0x404040, 0.2); // Reduced ambient light
            scene.add(ambientLight);

            // New: create a single point light that will be moved to highlight cards
            highlightLight = new THREE.PointLight(0xffffff, 1, 50);
            highlightLight.position.set(0, 5, -5); // Default position
            scene.add(highlightLight);
            
            // Create the mouse torch light
            torchLight = new THREE.SpotLight(0xffffff, 3, 20, Math.PI/6, 0.5, 1);
            torchLight.position.set(0, 0, 5);
            torchLight.castShadow = true;
            torchLight.shadow.mapSize.width = 1024;
            torchLight.shadow.mapSize.height = 1024;
            scene.add(torchLight);
            
            // Add light target
            const lightTarget = new THREE.Object3D();
            scene.add(lightTarget);
            torchLight.target = lightTarget;
            
            // Add floor
            const floorGeometry = new THREE.PlaneGeometry(50, 50);
            const floorMaterial = new THREE.MeshLambertMaterial({ 
                color: 0x222222,
                transparent: true,
                opacity: 0.8
            });
            const floor = new THREE.Mesh(floorGeometry, floorMaterial);
            floor.rotation.x = -Math.PI / 2;
            floor.position.y = -2;
            floor.receiveShadow = true;
            scene.add(floor);
            
            // Setup event listeners for user interaction
            setupEventListeners();
            
            // Show custom cursor
            document.getElementById('custom-cursor').style.display = 'block';
            cursorVisible = true;
            
            // Start the animation loop
            animate();
            
            // Load and display the initial AI models
            loadModels();
        }
        
        /**
         * Sets up all the event listeners for mouse, keyboard, and UI buttons.
         */
        function setupEventListeners() {
            window.addEventListener('mousemove', onMouseMove);
            window.addEventListener('click', onMouseClick);
            window.addEventListener('resize', onWindowResize);
            window.addEventListener('wheel', onMouseWheel); // Add mouse wheel for zoom
            
            window.addEventListener('keydown', onKeyDown);
            window.addEventListener('keyup', onKeyUp);
            
            document.getElementById('build-btn').addEventListener('click', buildVRChatUI);
            document.getElementById('send-btn').addEventListener('click', sendPrompt);
        }

        /**
         * Handles mouse movement for camera rotation and object highlighting.
         * @param {MouseEvent} event
         */
        function onMouseMove(event) {
            // Update the mouse position for raycasting
            mouse.x = (event.clientX / window.innerWidth) * 2 - 1;
            mouse.y = -(event.clientY / window.innerHeight) * 2 + 1;
            
            // Update custom cursor position
            const cursor = document.getElementById('custom-cursor');
            cursor.style.left = `${event.clientX}px`;
            cursor.style.top = `${event.clientY}px`;
            
            // Simple camera rotation with left mouse button
            if (event.buttons === 1) {
                camera.rotation.y -= event.movementX * 0.002;
                camera.rotation.x -= event.movementY * 0.002;
                camera.rotation.x = Math.max(-Math.PI/2, Math.min(Math.PI/2, camera.rotation.x));
            }

            // Update torch light to follow mouse position
            updateTorchLight();
        }

        /**
         * Updates the torch light to follow the mouse pointer
         */
        function updateTorchLight() {
            // Position the torch light at the camera
            torchLight.position.copy(camera.position);
            
            // Calculate where the mouse is pointing in 3D space
            raycaster.setFromCamera(mouse, camera);
            
            // Create a plane at z=0 to intersect with
            const plane = new THREE.Plane(new THREE.Vector3(0, 0, 1), 0);
            const intersectPoint = new THREE.Vector3();
            raycaster.ray.intersectPlane(plane, intersectPoint);
            
            // Point the light toward the intersection point
            torchLight.target.position.copy(intersectPoint);
        }

        /**
         * Handles mouse wheel events for camera zoom.
         * @param {WheelEvent} event
         */
        function onMouseWheel(event) {
            // Adjust camera position based on scroll direction
            camera.position.z += event.deltaY * 0.005;
        }
        
        /**
         * Handles mouse click events to select/deselect AI models.
         * @param {MouseEvent} event
         */
        function onMouseClick(event) {
            // Disable selection after the VR UI has been built
            if (isBuilt) return;
            
            raycaster.setFromCamera(mouse, camera);
            const intersects = raycaster.intersectObjects(modelGroups.map(group => group.children[0])); // Only check the cubes
            
            if (intersects.length > 0) {
                const selectedCube = intersects[0].object;
                toggleModelSelection(selectedCube);
            }
        }
        
        /**
         * Handles keyboard key presses for camera movement.
         * @param {KeyboardEvent} event
         */
        function onKeyDown(event) {
            switch(event.code) {
                case 'KeyW': moveForward = true; break;
                case 'KeyS': moveBackward = true; break;
                case 'KeyA': moveLeft = true; break;
                case 'KeyD': moveRight = true; break;
            }
        }
        
        /**
         * Handles keyboard key releases to stop camera movement.
         * @param {KeyboardEvent} event
         */
        function onKeyUp(event) {
            switch(event.code) {
                case 'KeyW': moveForward = false; break;
                case 'KeyS': moveBackward = false; break;
                case 'KeyA': moveLeft = false; break;
                case 'KeyD': moveRight = false; break;
            }
        }
        
        /**
         * Adjusts the camera and renderer when the window is resized.
         */
        function onWindowResize() {
            camera.aspect = window.innerWidth / window.innerHeight;
            camera.updateProjectionMatrix();
            renderer.setSize(window.innerWidth, window.innerHeight);
        }
        
        /**
         * Updates the camera position based on keyboard input.
         */
        function updateCamera() {
            const direction = new THREE.Vector3();
            camera.getWorldDirection(direction);

            if (moveForward) {
                camera.position.addScaledVector(direction, 0.1);
            }
            if (moveBackward) {
                camera.position.addScaledVector(direction, -0.1);
            }
            if (moveLeft) {
                const left = new THREE.Vector3().crossVectors(direction, camera.up);
                camera.position.addScaledVector(left, -0.1);
            }
            if (moveRight) {
                const right = new THREE.Vector3().crossVectors(direction, camera.up);
                camera.position.addScaledVector(right, 0.1);
            }
        }
        
        /**
         * Simulates an API call to load AI models or falls back to mock data.
         */
        async function loadModels() {
            document.getElementById('status').textContent = 'Loading models...';
            document.getElementById('loader').classList.remove('hidden');
            
            try {
                // Simulate fetching from an API. Will fall back to mock data if the API is not available.
                const response = await fetch('/api/ai/models?maxToShow=20');
                if (!response.ok) {
                    allModels = generateMockModels();
                } else {
                    allModels = await response.json();
                }
                
                createModelCubes();
                document.getElementById('status').textContent = `Loaded ${allModels.length} models. Click to select!`;
            } catch (error) {
                console.error('Error loading models:', error);
                allModels = generateMockModels();
                createModelCubes();
                document.getElementById('status').textContent = `Demo mode: ${allModels.length} mock models loaded`;
            } finally {
                document.getElementById('loader').classList.add('hidden');
                document.getElementById('build-btn').disabled = false;
            }
        }
        
        /**
         * Generates mock data for AI models for demonstration purposes.
         */
        function generateMockModels() {
            const providers = ['Gemini', 'Anthropic', 'AI21', 'Cohere', 'Meta'];
            const models = [];
            
            for (let i = 0; i < 12; i++) {
                models.push({
                    modelId: `model-${i + 1}`,
                    modelName: `AI Model ${i + 1}`,
                    providerName: providers[i % providers.length],
                });
            }
            return models;
        }
        
        /**
         * Creates the 3D cube representations for each AI model.
         */
        function createModelCubes() {
            const gridSize = Math.ceil(Math.sqrt(allModels.length));
            const spacing = 3;
            [...allModels].reverse().forEach((model, index) => {
                const row = Math.floor(index / gridSize);
                const col = index % gridSize;
                
                // Create a group to hold the cube and its label
                const group = new THREE.Group();
                group.position.set(
                    (col - gridSize/2 + 0.5) * spacing,
                    2,
                    (row - gridSize/2 + 0.5) * spacing
                );
                
                // Donut geometry
                const geometry = new THREE.TorusGeometry(
                    0.7,   // radius (overall size of donut)
                    0.10,  // tube (thickness of the donut ring)
                    16,    // radialSegments (smoothness around tube)
                    100    // tubularSegments (smoothness around circle)
                );

                const material = new THREE.MeshPhongMaterial({
                    color: 0x3498db,
                    transparent: true,
                    opacity: 0.8
                });
                
                const cube = new THREE.Mesh(geometry, material);
                cube.castShadow = true;
                cube.userData = { model, selected: false, index };
                group.add(cube); // Add cube to the group
                cube.position.y += 2; // Raise the cube above the ground
                
                // Create text label
                const textGeometry = new THREE.PlaneGeometry(2, 0.7);
                const canvas = document.createElement('canvas');
                canvas.width = 256;
                canvas.height = 64;
                const context = canvas.getContext('2d');
                context.fillStyle = 'rgba(0, 0, 0, 0.2)';
                context.fillRect(0, 0, 256, 64);
                context.fillStyle = '#ffffff';
                context.font = '16px Arial';
                context.textAlign = 'center';
                context.fillText(model.modelName, 128, 32);
                context.font = '16px Arial';
                context.fillText(model.providerName, 128, 48);
                
                const textTexture = new THREE.CanvasTexture(canvas);
                const textMaterial = new THREE.MeshBasicMaterial({ 
                    map: textTexture, 
                    transparent: true 
                });
                const textMesh = new THREE.Mesh(textGeometry, textMaterial);
                textMesh.position.y += 3.5;
                textMesh.lookAt(camera.position);
                group.add(textMesh); // Add text to the group
                
                scene.add(group);
                modelGroups.push(group);
            });
        }
        
        /**
         * Toggles the selection state of a 3D model cube.
         * @param {THREE.Mesh} cube The cube mesh that was clicked.
         */
        function toggleModelSelection(cube) {
            const model = cube.userData.model;
            const isSelected = cube.userData.selected;
            
            // Changed the max selection limit to 3
            if (isSelected) {
                cube.material.color.setHex(0x3498db); // Deselect color
                cube.userData.selected = false;
                selectedModels = selectedModels.filter(m => m.modelId !== model.modelId);
            } else {
                if (selectedModels.length >= 3) {
                    document.getElementById('status').textContent = 'Maximum 3 models can be selected';
                    return;
                }
                cube.material.color.setHex(0xe74c3c); // Select color
                cube.userData.selected = true;
                selectedModels.push(model);
            }
            
            updateUI();
        }
        
        /**
         * Updates the UI elements based on the current selection state.
         */
        function updateUI() {
            document.getElementById('model-count').textContent = `Selected Models: ${selectedModels.length}`;
            document.getElementById('build-btn').disabled = selectedModels.length === 0;
        }

        /**
         * Clears all 3D model cubes from the scene.
         */
        function clearModelCubes() {
            modelGroups.forEach(group => {
                // Recursively dispose of geometries and materials to prevent memory leaks
                group.traverse(object => {
                    if (object.isMesh) {
                        object.geometry.dispose();
                        object.material.dispose();
                    }
                });
                scene.remove(group);
            });
            modelGroups = []; // Reset the array
        }
        
        /**
         * Builds the VR chat UI by clearing old models and creating new response windows.
         */
        function buildVRChatUI() {
            if (selectedModels.length === 0 || selectedModels.length>3) {
                document.getElementById('status').textContent = 'Select 1 to 3 models before building the UI';
                return;
            }
            document.getElementById('videoSection').style.display = 'block';
            
            isBuilt = true;
            
            // Remove all existing model cubes
            clearModelCubes();

            // Set the highlight light to an invisible position
            highlightLight.position.set(0, 100, 0);
            
            // Hide the build button and show the prompt section
            document.getElementById('build-btn').classList.add('hidden');
            document.getElementById('prompt-section').classList.remove('hidden');
            document.getElementById('status').textContent = 'VR Chat UI built! Enter your prompt above.';
            
            // Create response windows in 3D space
            createResponseWindows();
        }

        let videoMesh = null;
        let videoMeshCtxt = null;

        function mapVideoTextureWhenVideoLoaded(windowMesh, model, canvas, context, textureOriginal) {
            const video = document.getElementById("video");
            document.getElementById("videoUpload").addEventListener("change", async (event) => {
                if(!cocoSsdModel) {
                    cocoSsd.load().then(model => {
                    cocoSsdModel = model;
                    document.getElementById('inferChk').disabled = false;
                    document.getElementById('inferChk').addEventListener('change', (e) => {
                    if(e.target.checked) {
                        video.pause();
                        runInferenceOnCurrentFrame(windowMesh);
                    } else {
                        video.play();
                    }});
                    console.log("cocoSsdModel",cocoSsdModel);
                    });
                }
                const file = event.target.files[0];
                if (!file) return;

                const formData = new FormData();
                formData.append("video", file);

                const res = await fetch("/api/upload", { method: "POST", body: formData });
                const data = await res.json();
                video.src = data.videoUrl;
                await video.play();

                const texture = new THREE.VideoTexture(video);
                windowMesh.material.map = texture;
                windowMesh.material.needsUpdate = true;
                videoMesh = windowMesh;
                videoMeshCtxt = { model, canvas, context, texture: textureOriginal };
            });
        }

            async function runInferenceOnCurrentFrame(windowMesh) {
                try {
                    // Create temporary canvas for the current frame
                    const inferenceCanvas = document.createElement('canvas');
                    const inferenceCtx = inferenceCanvas.getContext('2d');
                    inferenceCanvas.width = video.videoWidth;
                    inferenceCanvas.height = video.videoHeight;

                    // Draw the current paused video frame
                    inferenceCtx.drawImage(video, 0, 0, inferenceCanvas.width, inferenceCanvas.height);

                    // Run COCO-SSD inference on the current frame
                    cocoSsdModel.detect(inferenceCanvas).then(predictions => {
                        console.log("Predictions:", predictions);
                        console.log("Frame inference complete. Detected:", predictions);
                        overlayPredictions(predictions, windowMesh);
                    });
                } catch (error) {
                    console.error("Inference error:", error);
                }
            }

            function overlayPredictions(predictions, mesh) {
                // Clear previous overlays first
                //clearOverlays();

                console.log("Detected objects:", predictions);

                predictions.forEach(prediction => {
                    const { bbox, class: className, score } = prediction;
                    if (score > 0.5) { // Only show confident detections
                        createBoundingBoxOverlay(bbox, className, score, mesh);
                    }
                });
            }


            function createBoundingBoxOverlay(bbox, className, score, mesh) {
                // Create 3D bounding box or 2D overlay on the video texture
                // Convert 2D bbox coordinates to 3D space relative to the mesh
                const [x, y, width, height] = bbox;

                // Use PlaneGeometry for a flat rectangle
                const geometry = new THREE.PlaneGeometry(width / 100, height / 100);

                // Extract only the outline (edges)
                const edges = new THREE.EdgesGeometry(geometry);
                const material = new THREE.LineBasicMaterial({ color: 0x00ff00, linewidth: 2 });
                const boxMesh = new THREE.LineSegments(edges, material);

                // Position correctly
                boxMesh.position.set(
                    (x + width / 2 - video.videoWidth / 2) / 100,
                    (-y - height / 2 + video.videoHeight / 2) / 100,
                    0.1
                );

                mesh.add(boxMesh);

                const labelText = `${className} ${(score * 100).toFixed(1)}%`;
                const label = makeTextSprite(labelText, { fontsize: 30, borderThickness: 2 });
                label.position.set(
                    (x + width / 2 - video.videoWidth / 2) / 100,
                    (-y - height / 2 + video.videoHeight / 2) / 100, // ðŸ‘ˆ a bit above the box
                    0.1
                );

                mesh.add(label);
            }

            function makeTextSprite(message, parameters) {
                const fontface = parameters?.fontface || "Arial";
                const fontsize = parameters?.fontsize || 20;
                const borderThickness = parameters?.borderThickness || 2;

                const canvas = document.createElement("canvas");
                const context = canvas.getContext("2d");
                context.font = fontsize + "px " + fontface;

                // Draw background (semi-transparent)
                /*context.fillStyle = "rgba(0, 0, 0, 0.5)";
                context.fillRect(0, 0, canvas.width, canvas.height);*/

                // Draw text
                context.fillStyle = "rgba(0, 255, 0, 1.0)";
                context.textAlign = "left";
                context.textBaseline = "middle";
                context.fillText(message, borderThickness * 2, canvas.height / 2);

                // Convert to texture
                const texture = new THREE.CanvasTexture(canvas);
                const spriteMaterial = new THREE.SpriteMaterial({ map: texture, transparent: true, alphaTest: 0.01 });
                const sprite = new THREE.Sprite(spriteMaterial);

                // Default reasonable scale
                sprite.scale.set(2, 2, 2);
                return sprite;
            }
        /**
         * Creates the 3D chat windows for each selected AI model.
         */
        function createResponseWindows() {
            const windowWidth = 12;
            const windowHeight = 9;
            const spacing = 12;
            
            selectedModels.forEach((model, index) => {
                // Create a group for the window
                const group = new THREE.Group();
                let position = [(index - (selectedModels.length - 1)/2) * spacing, 3,-5];
                console.log("position",position);
                group.position.set(...position);
                
                // Create window geometry
                const windowGeometry = new THREE.PlaneGeometry(windowWidth, windowHeight);
                const windowMaterial = new THREE.MeshPhongMaterial({ 
                    color: 0x2c3e50,
                    transparent: true,
                    opacity: 0.9,
                    side: THREE.DoubleSide
                });
                
                const windowMesh = new THREE.Mesh(windowGeometry, windowMaterial);
                group.add(windowMesh);
                
                // Create text canvas for responses
                // Increased canvas resolution for better text clarity
                const canvas = document.createElement('canvas');
                canvas.width = 1024;
                canvas.height = 768;
                const context = canvas.getContext('2d');
                
                const texture = new THREE.CanvasTexture(canvas);
                windowMesh.material.map = texture;
                windowMesh.userData = { model, canvas, context, texture };

                if (index === 0) {
                    mapVideoTextureWhenVideoLoaded(windowMesh, model, canvas, context, texture);
                }
                
                scene.add(group);
                responseWindows.push(windowMesh);

                updateResponseWindow(windowMesh, '', 'Ready for prompts...');
            });
        }
        
        /**
         * Sends the user's prompt to the selected models via the new API endpoint.
         */
        async function sendPrompt() {
            const prompt = document.getElementById('prompt-input').value.trim();
            if (!prompt) {
                document.getElementById('status').textContent = 'Please enter a prompt';
                return;
            }
            
            document.getElementById('status').textContent = 'Sending prompts...';
            document.getElementById('loader').classList.remove('hidden');
            
            // Clear previous responses and show a loading state
            responseWindows.forEach(window => {
                updateResponseWindow(window, prompt, 'Processing...');
            });

            if(videoMesh) {
                const video = document.getElementById("video");
                await video.pause();
                videoMesh.material = new THREE.MeshPhongMaterial({ 
                    color: 0x2c3e50,
                    transparent: true,
                    opacity: 0.9,
                    side: THREE.DoubleSide
                });
                videoMesh.material.map = videoMeshCtxt.texture;
                videoMesh.userData = videoMeshCtxt;
                videoMesh = null;
            }

            // Use Promise.all to handle all API calls concurrently
            const promises = selectedModels.map(model => {
                return fetch('/api/ai/invoke', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        modelId: model.modelId,
                        prompt: prompt
                    })
                }).then(response => response.json())
                    .then(result => ({
                        ...result,
                        modelId: model.modelId
                    }));
            });
            
            try {
                const results = await Promise.all(promises);
                
                // Update response windows with the actual results
                results.forEach((result) => {
                    const windowToUpdate = responseWindows.find(window => window.userData.model.modelId === result.modelId);
                    if (windowToUpdate) {
                        // Assuming the API response has a 'response' field with the text
                        const responseText = result.response || `No response field found from model ${result.modelId}`;
                        updateResponseWindow(windowToUpdate, prompt, responseText);
                    }
                });
                
                document.getElementById('status').textContent = 'Responses received!';
                document.querySelector('#ui-overlay').style.display = 'none';
                setTimeout(() => {
                    document.querySelector('#ui-overlay').style.display = 'block';
                }, 6000); // Briefly hide to force texture update
            } catch (error) {
                console.error('Error sending prompts:', error);
                document.getElementById('status').textContent = 'Error sending prompts';
            } finally {
                document.getElementById('loader').classList.add('hidden');
            }
        }
        
        /**
         * Updates the content of a 3D response window using a 2D canvas.
         * @param {THREE.Mesh} window The 3D window mesh.
         * @param {string} prompt The original user prompt.
         * @param {string} response The AI response text.
         */
        function updateResponseWindow(window, prompt, response) {
            const { context, texture, model, canvas } = window.userData;
            
            // Clear canvas
            context.fillStyle = 'rgba(44, 62, 80, 0.95)';
            context.fillRect(0, 0, canvas.width, canvas.height);
            
            // Header
            context.fillStyle = '#38bdf8';
            context.fillRect(0, 0, canvas.width, 100);
            context.fillStyle = 'white';
            context.font = 'bold 48px Arial';
            context.textAlign = 'center';
            context.fillText(model.modelName, canvas.width / 2, 65);
            
            // Content
            const padding = 40;
            const contentWidth = canvas.width - 2 * padding;
            let currentY = 140;
            const lineHeight = 30;

            context.textAlign = 'left';
            
            // Draw prompt
            context.font = 'bold 24px Arial';
            context.fillStyle = '#cbd5e1';
            context.fillText('Prompt:', padding, currentY);
            currentY += lineHeight;
            context.font = '24px Arial';
            wrapText(context, prompt, padding, currentY, contentWidth, lineHeight);
            
            // Calculate y position for the response based on prompt height
            const promptLines = Math.ceil(context.measureText(prompt).width / contentWidth);
            currentY += Math.max(promptLines, 1) * lineHeight + 40;

            // Draw response
            context.font = 'bold 24px Arial';
            context.fillStyle = '#4ade80';
            context.fillText('Response:', padding, currentY);
            currentY += lineHeight;
            context.font = '24px Arial';
            context.fillStyle = 'white';
            wrapText(context, response, padding, currentY, contentWidth, lineHeight);
            
            texture.needsUpdate = true;
        }
        
        /**
         * Wraps text to fit within a specific width on a canvas.
         */
        function wrapText(context, text, x, y, maxWidth, lineHeight) {
            if (!text) return;
            const words = text.split(' ');
            let line = '';
            let currentY = y;
            
            for (let n = 0; n < words.length; n++) {
                const testLine = line + words[n] + ' ';
                const metrics = context.measureText(testLine);
                const testWidth = metrics.width;
                
                if (testWidth > maxWidth && n > 0) {
                    context.fillText(line, x, currentY);
                    line = words[n] + ' ';
                    currentY += lineHeight;
                } else {
                    line = testLine;
                }
            }
            context.fillText(line, x, currentY);
        }
        
        /**
         * The main animation loop for the Three.js scene.
         */
        direction = 1; // Direction for rotation
        setInterval(() => {
            direction *= -1; // Reverse direction every 5 seconds
        }, 5000);
        function animate() {
            requestAnimationFrame(animate);
            
            updateCamera();
            
            // Rotate the initial model cubes slightly
            modelGroups.forEach(group => {
                group.rotation.y += (direction) * 0.001;
                group.rotation.x += (direction) * 0.001;
            });
            
            // Make response windows always face the camera
            responseWindows.forEach(window => {
                window.parent.lookAt(camera.position); // Look at the parent group, which contains the window and light
            });
            
            // Update torch light to follow mouse
            updateTorchLight();
            
            renderer.render(scene, camera);
        }
        
        // Start the application when the window loads
        window.addEventListener('load', init);
    </script>
</body>
</html>